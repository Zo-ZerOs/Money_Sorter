{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bbd33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pathlib import Path\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "PATIENCE = 5\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e23c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 32\n"
     ]
    }
   ],
   "source": [
    "folder_path = Path(\"dataset\")  # Change this to your folder path\n",
    "\n",
    "# Count only subdirectories\n",
    "CLASS_NUMBERS = sum(1 for entry in folder_path.iterdir() if entry.is_dir())\n",
    "\n",
    "print(f\"Number of classes: {CLASS_NUMBERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f886411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6827 files belonging to 32 classes.\n",
      "Using 4779 files for training.\n",
      "Found 6827 files belonging to 32 classes.\n",
      "Using 2048 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    \"dataset\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# print(\"Class indices:\", train_dataset.class_names)\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    \"dataset\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac43ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b2d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd5cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune only the last 100 layers\n",
    "fine_tune_at = len(base_model.layers) - 100\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a92f5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce851a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b4a9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "base_model.trainable = True  # Fully unfreeze\n",
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,  \n",
    "    layers.Lambda(preprocess_input),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.1),  # reduced\n",
    "    layers.Dense(128, activation='relu'),  # increased\n",
    "    # removed L2 and BatchNorm for now\n",
    "    layers.Dense(CLASS_NUMBERS, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # simpler optimizer\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a8fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\myFile\\KAIST\\3 Sem 2\\CS270. Intelligent robot design and programming\\Final Project\\teng2\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.3196 - loss: 2.5873 - val_accuracy: 0.6826 - val_loss: 1.0631\n",
      "Epoch 2/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 1s/step - accuracy: 0.9208 - loss: 0.3276 - val_accuracy: 0.8540 - val_loss: 0.5192\n",
      "Epoch 3/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.9843 - loss: 0.0924 - val_accuracy: 0.8975 - val_loss: 0.3675\n",
      "Epoch 4/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9827 - loss: 0.0661 - val_accuracy: 0.9526 - val_loss: 0.1827\n",
      "Epoch 5/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9903 - loss: 0.0488 - val_accuracy: 0.9546 - val_loss: 0.1596\n",
      "Epoch 6/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.9903 - loss: 0.0317 - val_accuracy: 0.9561 - val_loss: 0.1536\n",
      "Epoch 7/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 1s/step - accuracy: 0.9928 - loss: 0.0238 - val_accuracy: 0.9834 - val_loss: 0.0823\n",
      "Epoch 8/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.9934 - loss: 0.0245 - val_accuracy: 0.9814 - val_loss: 0.0803\n",
      "Epoch 9/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.9934 - loss: 0.0246 - val_accuracy: 0.9800 - val_loss: 0.0835\n",
      "Epoch 10/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.9951 - loss: 0.0194 - val_accuracy: 0.9692 - val_loss: 0.1083\n",
      "Epoch 11/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 1s/step - accuracy: 0.9943 - loss: 0.0189 - val_accuracy: 0.9854 - val_loss: 0.0686\n",
      "Epoch 12/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 1s/step - accuracy: 0.9949 - loss: 0.0143 - val_accuracy: 0.9824 - val_loss: 0.0822\n",
      "Epoch 13/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9948 - loss: 0.0180 - val_accuracy: 0.9761 - val_loss: 0.0951\n",
      "Epoch 14/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 1s/step - accuracy: 0.9950 - loss: 0.0206 - val_accuracy: 0.9829 - val_loss: 0.0753\n",
      "Epoch 15/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1s/step - accuracy: 0.9967 - loss: 0.0109 - val_accuracy: 0.9673 - val_loss: 0.1237\n",
      "Epoch 16/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.9947 - loss: 0.0186 - val_accuracy: 0.9761 - val_loss: 0.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved as 'banknote_classifier_mobilenetv2.h5'.\n"
     ]
    }
   ],
   "source": [
    "# Early stopping on validation accuracy\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"model/banknote_classifier_mobilenetv2.h5\")\n",
    "print(\"Model training complete and saved as 'banknote_classifier_mobilenetv2.h5'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teng2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
